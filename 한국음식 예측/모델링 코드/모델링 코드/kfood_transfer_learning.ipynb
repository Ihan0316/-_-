{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a42ee6b6b78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0. 작업 준비\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d1f0754b48329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 시각화\n",
    "def make_it_plt(dataset, class_names):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for images, labels in dataset.take(1):\n",
    "        # 전이 학습 모델에 맞는 입력 형식으로 변환 (0-1 사이 값)\n",
    "        images_to_show = images.numpy() / 255.0\n",
    "        for i in range(min(25, len(images))):\n",
    "            ax = plt.subplot(5, 5, i + 1)\n",
    "            plt.imshow(images_to_show[i])\n",
    "            plt.title(class_names[labels[i]])\n",
    "            plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be9ad2db3ed8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 (전이 학습)\n",
    "def model_create_transfer(input_shape, num_classes, optimizer_fn, loss_fn, metrics_fn):\n",
    "    # 1. 기반 모델(Base Model) 로드 (사전 학습된 가중치 사용)\n",
    "    base_model = tf.keras.applications.EfficientNetB4(\n",
    "        include_top=False, # 분류기는 직접 추가할 것이므로 False\n",
    "        weights='imagenet', # ImageNet으로 사전 학습된 가중치 사용\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "\n",
    "    # 2. 기반 모델의 가중치를 동결 (초기 학습 단계에서는 변경되지 않도록)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # 3. 새로운 모델 구성 (Functional API 사용)\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # EfficientNetB4는 자체적으로 Rescaling을 포함하므로 별도 레이어 필요 없음\n",
    "    x = base_model(inputs, training=False) # BatchNormalization 레이어가 동결되도록 training=False\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.3)(x) # 과적합 방지\n",
    "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_fn)\n",
    "    model.summary()\n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614f0faede96c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 메인 실행 로직 ---\n",
    "\n",
    "# 랜덤 난수 고정\n",
    "seed = 53\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 데이터셋 경로 및 파라미터\n",
    "DATA_PATH = '/Users/ihanjo/Documents/미니 프로젝트/한국음식 예측/데이터/한국 음식 이미지/kfood'\n",
    "MODEL_PATH = '../model'\n",
    "IMG_SIZE = (224, 224) # EfficientNetB4 권장 사이즈\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# 데이터셋 로드\n",
    "print(\"Loading training and validation datasets...\")\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "print(f\"Found {len(class_names)} classes.\")\n",
    "\n",
    "# 데이터 로딩 파이프라인 최적화\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# 모델 옵티마이저, 손실함수, 평가지표 정의\n",
    "op = keras.optimizers.Adam(learning_rate=0.001)\n",
    "ls = keras.losses.SparseCategoricalCrossentropy()\n",
    "acc = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# 모델 생성\n",
    "model, base_model = model_create_transfer(\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    num_classes=len(class_names),\n",
    "    optimizer_fn=op,\n",
    "    loss_fn=ls,\n",
    "    metrics_fn=[acc]\n",
    ")\n",
    "\n",
    "# 모델 callback 정의\n",
    "es = EarlyStopping(patience=5, monitor=\"val_loss\", restore_best_weights=True, verbose=1)\n",
    "ck_path = \"../model/modelbest_kfood_transfer_model.keras\"\n",
    "ck = ModelCheckpoint(ck_path, save_best_only=True, monitor='val_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d45e8da2eb8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1단계: 전이 학습 ---\n",
    "print(\"\\n--- Phase 1: Transfer Learning ---\")\n",
    "history_transfer = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=10,\n",
    "    callbacks=[es, ck]\n",
    ")\n",
    "\n",
    "# --- 2단계: 미세 조정 (Fine-tuning) ---\n",
    "print(\"\\n--- Phase 2: Fine-tuning ---\")\n",
    "base_model.trainable = True # 기반 모델 동결 해제\n",
    "\n",
    "# 상위 일부 레이어만 학습 가능하도록 설정 (예: 마지막 20개 레이어)\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de700bd3148e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_transfer.history['loss'])\n",
    "plt.plot(history_transfer.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1309cc5d23c7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매우 낮은 학습률로 모델을 다시 컴파일\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=ls,\n",
    "    metrics=[acc]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=10, # Fine-tuning은 보통 짧게 진행\n",
    "    initial_epoch=history_transfer.epoch[-1] + 1, # 이전 학습에 이어서 시작\n",
    "    callbacks=[es, ck] # 동일한 콜백 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5473a7ee14421",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_fine.history['loss'])\n",
    "plt.plot(history_fine.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b580ce86dd1042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 최종 평가 및 예측 ---\n",
    "\n",
    "print(\"\\n--- Final Evaluation and Prediction ---\")\n",
    "# 가장 성능이 좋았던 모델 로드\n",
    "best_model = load_model(ck_path)\n",
    "\n",
    "loss, accuracy = best_model.evaluate(validation_dataset)\n",
    "print(f\"Final Validation Loss: {loss:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nTesting prediction on a sample batch...\")\n",
    "for test_images, test_labels in validation_dataset.take(1):\n",
    "    predictions = best_model.predict(test_images)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    true_class_names = [class_names[i] for i in test_labels.numpy()[:10]]\n",
    "    predicted_class_names = [class_names[i] for i in predicted_labels[:10]]\n",
    "    print(f\"\\nTrue Food Names:      {true_class_names}\")\n",
    "    print(f\"Predicted Food Names: {predicted_class_names}\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-mps)",
   "language": "python",
   "name": "tf-mps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
